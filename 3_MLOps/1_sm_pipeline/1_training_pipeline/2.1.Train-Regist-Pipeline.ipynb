{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2.1] 모델 훈련 스텝 및 모델 등록 스텝 개발 (SageMaker Model Building Pipeline 훈련 스텝)\n",
    "\n",
    "이 노트북은 아래와 같은 목차로 진행 됩니다. 전체를 모두 실행시에 완료 시간은 약 5분-10분 소요 됩니다.\n",
    "\n",
    "- 0. 환경 세팅\n",
    "- 1. 모델 훈련 스텝 개발 및 실행\n",
    "- 2. 모델 평가 파일 다운로드\n",
    "- 3. SageMaker Pipeline에서 실행\n",
    "- 4. 모델 레지스트리에서 모델 등록 확인\n",
    "- 5. 리소스 정리: 파이프라인\n",
    "\n",
    "---\n",
    "### 노트북 커널\n",
    "- 이 워크샵은 노트북 커널이 `conda_python3` 를 사용합니다. 다른 커널일 경우 변경 해주세요.\n",
    "---\n",
    "\n",
    "### 참고\n",
    "- [Amazon SageMaker Model Building Pipeline](https://sagemaker.readthedocs.io/en/v2.92.2/amazon_sagemaker_model_building_pipeline.html#amazon-sagemaker-model-building-pipeline)\n",
    "- [아마존 SageMaker 모델 구축 파이프라인](https://us-east-1.console.aws.amazon.com/codesuite/codepipeline/pipelines/ncf-training-code-pipeline/view?region=us-east-1)\n",
    "- 모델 등록 스텝은 여기를 참조 바랍니다. --> [모델 레지스트리로 모델 등록 및 배포](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-registry.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 환경 세팅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 변수를 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s3_input_data_uri\n",
    "%store -r bucket\n",
    "%store -r project_prefix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이타가 존재하는지 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to locate credentials. You can configure credentials by running \"aws configure\".\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {s3_input_data_uri} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모델 훈련 스텝 개발 및 실행\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. 훈련 및 테스트 데이터를 S3 로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_inputs: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/NCFModel/data', 'test': 's3://sagemaker-us-east-1-057716757052/NCFModel/data'}\n"
     ]
    }
   ],
   "source": [
    "s3_inputs = {\n",
    "            'train': f'{s3_input_data_uri}',\n",
    "            'test': f'{s3_input_data_uri}'\n",
    "            }\n",
    "\n",
    "print(\"s3_inputs: \\n\", s3_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "       {'Name': 'HR', 'Regex': 'HR=(.*?);'},\n",
    "       {'Name': 'NDCG', 'Regex': 'NDCG=(.*?);'},\n",
    "       {'Name': 'Loss', 'Regex': 'Loss=(.*?);'}        \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "hyperparameters = {'epochs': 1, \n",
    "                       'lr': 0.001,\n",
    "                       'batch_size': 256,\n",
    "                       'top_k' : 10,\n",
    "                       'dropout' : 0.0,\n",
    "                       'factor_num' : 32,\n",
    "                       'num_layers' : 3,\n",
    "                       'num_ng' : 4,\n",
    "                       'test_num_ng' : 99,                   \n",
    "                    }  \n",
    "\n",
    "\n",
    "host_estimator = PyTorch(\n",
    "    entry_point=\"train_metric.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    session = sagemaker.Session(), # 세이지 메이커 세션\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions = metric_definitions\n",
    "\n",
    ")\n",
    "host_estimator.fit(s3_inputs, \n",
    "                   # experiment_config = experiment_config, # 실험 설정 제공                   \n",
    "                   wait=False)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 10:29:59 Starting - Starting the training job...\n",
      "2022-07-08 10:30:28 Starting - Preparing the instances for trainingProfilerReport-1657276199: InProgress\n",
      ".........\n",
      "2022-07-08 10:31:59 Downloading - Downloading input data\n",
      "2022-07-08 10:31:59 Training - Downloading the training image.................................\n",
      "2022-07-08 10:37:14 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-07-08 10:37:14,164 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-08 10:37:14,188 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-08 10:37:14,195 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-08 10:37:14,665 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: nvidia-ml-py3==7.352 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (7.352.0)\u001b[0m\n",
      "\u001b[34mCollecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy==1.16.6\n",
      "  Downloading numpy-1.16.6-cp36-cp36m-manylinux1_x86_64.whl (17.4 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==1.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting gensim==3.7.1\n",
      "  Downloading gensim-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboardX==1.6\n",
      "  Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas==0.24.2->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch==1.8.1->-r requirements.txt (line 4)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smart-open>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from gensim==3.7.1->-r requirements.txt (line 5)) (5.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX==1.6->-r requirements.txt (line 6)) (3.19.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, tensorboardX, pandas, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled pandas-1.1.5\u001b[0m\n",
      "\u001b[34mSuccessfully installed gensim-3.7.1 numpy-1.16.6 pandas-0.24.2 tensorboardX-1.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-07-08 10:37:30,026 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 256,\n",
      "        \"dropout\": 0.0,\n",
      "        \"epochs\": 1,\n",
      "        \"factor_num\": 32,\n",
      "        \"lr\": 0.001,\n",
      "        \"num_layers\": 3,\n",
      "        \"num_ng\": 4,\n",
      "        \"test_num_ng\": 99,\n",
      "        \"top_k\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-07-08-10-29-59-553\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_metric\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_metric.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_metric.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_metric\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":256,\"dropout\":0.0,\"epochs\":1,\"factor_num\":32,\"lr\":0.001,\"num_layers\":3,\"num_ng\":4,\"test_num_ng\":99,\"top_k\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-07-08-10-29-59-553\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/source/sourcedir.tar.gz\",\"module_name\":\"train_metric\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_metric.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"256\",\"--dropout\",\"0.0\",\"--epochs\",\"1\",\"--factor_num\",\"32\",\"--lr\",\"0.001\",\"--num_layers\",\"3\",\"--num_ng\",\"4\",\"--test_num_ng\",\"99\",\"--top_k\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_FACTOR_NUM=32\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LAYERS=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_NG=4\u001b[0m\n",
      "\u001b[34mSM_HP_TEST_NUM_NG=99\u001b[0m\n",
      "\u001b[34mSM_HP_TOP_K=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_metric.py --batch_size 256 --dropout 0.0 --epochs 1 --factor_num 32 --lr 0.001 --num_layers 3 --num_ng 4 --test_num_ng 99 --top_k 10\u001b[0m\n",
      "\u001b[34m##### Args: \n",
      " Namespace(batch_size=256, dropout=0.0, epochs=1, factor_num=32, gpu='0', lr=0.001, model_dir='/opt/ml/model', num_layers=3, num_ng=4, out=True, output_data_dir='/opt/ml/output/data', test_data_dir='/opt/ml/input/data/test', test_num_ng=99, top_k=10, train_data_dir='/opt/ml/input/data/train')\u001b[0m\n",
      "\u001b[34margs.train_data_dir: \u001b[0m\n",
      "\u001b[34margs.test_data_dir: \u001b[0m\n",
      "\u001b[34margs.model_dir: \u001b[0m\n",
      "\u001b[34m=====> data loading <===========\u001b[0m\n",
      "\u001b[34mGet train data sampler and data loader\u001b[0m\n",
      "\u001b[34mGet test data sampler and data loader\u001b[0m\n",
      "\u001b[34mPretrained model is NOT used\u001b[0m\n",
      "\u001b[34mlabels_ps:  994169\u001b[0m\n",
      "\u001b[34mlabels_ng:  3976676\u001b[0m\n",
      "\u001b[34mtotal train size :  4970845\u001b[0m\n",
      "\u001b[34m=====> Starting New Traiing <===========\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.642 algo-1:32 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.749 algo-1:32 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.750 algo-1:32 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.750 algo-1:32 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.751 algo-1:32 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:22.751 algo-1:32 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.192 algo-1:32 INFO hook.py:591] name:embed_user_GMF.weight count_params:193280\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.192 algo-1:32 INFO hook.py:591] name:embed_item_GMF.weight count_params:118592\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:embed_user_MLP.weight count_params:773120\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:embed_item_MLP.weight count_params:474368\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.4.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.4.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.7.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:MLP_layers.7.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:predict_layer.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.193 algo-1:32 INFO hook.py:591] name:predict_layer.bias count_params:1\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.194 algo-1:32 INFO hook.py:593] Total Trainable Params: 1602657\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.194 algo-1:32 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-07-08 10:38:24.197 algo-1:32 INFO hook.py:488] Hook is writing from the hook with pid: 32\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [256000/4970845 (5%)] Loss=0.301850;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [512000/4970845 (10%)] Loss=0.324728;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [768000/4970845 (15%)] Loss=0.317688;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [1024000/4970845 (21%)] Loss=0.287539;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [1280000/4970845 (26%)] Loss=0.304610;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [1536000/4970845 (31%)] Loss=0.309476;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [1792000/4970845 (36%)] Loss=0.329028;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [2048000/4970845 (41%)] Loss=0.339956;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [2304000/4970845 (46%)] Loss=0.313296;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [2560000/4970845 (51%)] Loss=0.277023;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [2816000/4970845 (57%)] Loss=0.291452;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [3072000/4970845 (62%)] Loss=0.227466;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [3328000/4970845 (67%)] Loss=0.300375;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [3584000/4970845 (72%)] Loss=0.289638;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [3840000/4970845 (77%)] Loss=0.324576;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [4096000/4970845 (82%)] Loss=0.232639;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [4352000/4970845 (88%)] Loss=0.281923;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [4608000/4970845 (93%)] Loss=0.317138;\u001b[0m\n",
      "\u001b[34mTrain Epoch: 0 [4864000/4970845 (98%)] Loss=0.248437;\u001b[0m\n",
      "\u001b[34mThe time elapse of epoch 000 is: 00: 02: 29\u001b[0m\n",
      "\u001b[34mcuda\u001b[0m\n",
      "\u001b[34mHR=0.630; #011 NDCG=0.364;\u001b[0m\n",
      "\u001b[34mbest_hr:  0.6299668874172185\u001b[0m\n",
      "\u001b[34mthe model is saved at /opt/ml/model/NeuMF-end.pth\u001b[0m\n",
      "\u001b[34mEnd. Best epoch 000: HR = 0.630, NDCG = 0.364\u001b[0m\n",
      "\u001b[34m###### metrics is saved  at /opt/ml/output/data/metrics.json with best_hr: 0.63 best_ndcg : 0.364  \u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [256000/4970845 (5%)] Loss=0.301850;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [512000/4970845 (10%)] Loss=0.324728;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [768000/4970845 (15%)] Loss=0.317688;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [1024000/4970845 (21%)] Loss=0.287539;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [1280000/4970845 (26%)] Loss=0.304610;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [1536000/4970845 (31%)] Loss=0.309476;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [1792000/4970845 (36%)] Loss=0.329028;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [2048000/4970845 (41%)] Loss=0.339956;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [2304000/4970845 (46%)] Loss=0.313296;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [2560000/4970845 (51%)] Loss=0.277023;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [2816000/4970845 (57%)] Loss=0.291452;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [3072000/4970845 (62%)] Loss=0.227466;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [3328000/4970845 (67%)] Loss=0.300375;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [3584000/4970845 (72%)] Loss=0.289638;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [3840000/4970845 (77%)] Loss=0.324576;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [4096000/4970845 (82%)] Loss=0.232639;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [4352000/4970845 (88%)] Loss=0.281923;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [4608000/4970845 (93%)] Loss=0.317138;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:Train Epoch: 0 [4864000/4970845 (98%)] Loss=0.248437;\u001b[0m\n",
      "\u001b[34mINFO:train_lib:###### metrics is saved  at /opt/ml/output/data/metrics.json with best_hr: 0.63 best_ndcg : 0.364  \u001b[0m\n",
      "\u001b[34m2022-07-08 10:41:16,960 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-08 10:41:35 Uploading - Uploading generated training model\n",
      "2022-07-08 10:41:35 Completed - Training job completed\n",
      "Training seconds: 584\n",
      "Billable seconds: 584\n"
     ]
    }
   ],
   "source": [
    "## 마지막 estimator의 로그 출력\n",
    "host_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 평가 파일 다운로드\n",
    "\n",
    "이 단계는 model registry 에 모델을 등록시에 모델의 성능 메트릭을 넣기위한 단계 입니다. 이후 model restry 단계에서 치종 결과인 메트릭의 S3 경로를 사용할 예정 입니다.\n",
    "\n",
    "- 아래 작업은 모델 훈련을 하면서 모델의 평가 (Train:Auc, Validation:Auc) 의 값을 'metrics.json' 에 저장을 하고, 도커 안의 환경 변수가 가르키는 곳에  (SM_OUTPUT_DATA_DIR=/opt/ml/output/data) 저장을 합니다.\n",
    "- metrics.json 파일을 훈련이 끝난 후에 아래와 같은 경로 (에: s3://sagemaker-us-east-1-057716757052/sagemaker-pipeline-step-by-step-phase02/training_jobs/sagemaker-xgboost-2022-06-23-12-25-31-125/output/output.tar.gz) 에 업로딩 합니다. \n",
    "- 이 파일을 로컬 폴더 (에: ./output) 에 다운로드 하고, 압축을 해제 합니다.\n",
    "- 'metrics.json' 파일을 S3 에 업로드 하여 s3_uri 경로를 저장 합니다.\n",
    "- s3_uri 는 model registry 에 모델을 등록시에 인자로 제공하여 , 모델의 성능 메트릭을 관리 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_artifact_path: s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "output_artifact_path = f\"{host_estimator.output_path}{host_estimator.latest_training_job.job_name}/output/output.tar.gz\"\n",
    "print(f\"output_artifact_path: {output_artifact_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-08 10:41:26        205 output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {output_artifact_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_dir = './output'\n",
    "os.makedirs(output_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/output/output.tar.gz\n",
      "./output\n",
      "download: s3://sagemaker-us-east-1-057716757052/pytorch-training-2022-07-08-10-29-59-553/output/output.tar.gz to output/output.tar.gz\n",
      "metrics.json\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {output_artifact_path} {output_data_dir}\n",
    "\n",
    "output_artifact_path=$1\n",
    "output_data_dir=$2\n",
    "\n",
    "echo $output_artifact_path\n",
    "echo $output_data_dir\n",
    "\n",
    "\n",
    "# 모델을 S3에서 로컬로 다운로드\n",
    "aws s3 cp $output_artifact_path $output_data_dir\n",
    "\n",
    "# # 모델 다운로드 폴더로 이동\n",
    "cd $output_data_dir\n",
    "\n",
    "# # 압축 해제\n",
    "tar -xvf output.tar.gz  \n",
    "\n",
    "rm -rf output.tar.gz  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로컬의 metrics.json 을 S3에 업로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/NCFModel/metrics.json\n"
     ]
    }
   ],
   "source": [
    "metric_path = os.path.join(output_data_dir, 'metrics.json')\n",
    "metric_data_uri = f\"s3://{bucket}/{project_prefix}\"\n",
    "\n",
    "metric_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=metric_path, \n",
    "    desired_s3_uri=metric_data_uri,    \n",
    ")\n",
    "print(metric_data_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SageMaker Pipeline에서  실행 \n",
    "- 모델 훈련 스텝과 모델 등록 스텝 두가지를 실행합니다.\n",
    "    - 두 개의 단계가 서로 의존성이 있기에, 두 개의 단계를 연결을 합니다.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌딩 파이프라인 변수 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "s3_data_loc = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=s3_input_data_uri,\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습을 위한 학습단계 정의 \n",
    "\n",
    "본 단계에서는 SageMaker의 [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) 알고리즘을 이용하여 학습을 진행할 것입니다. XGBoost 알고리즘을 이용하도록 Estimator를 구성합니다. 보편적인 학습스크립트를 이용하여 입력 채널에서 정의한 학습데이터를 로드하고, 하이퍼파라미터 설정을 통해 학습을 설정하고, 모델을 학습한 후 `model_dir`경로에 학습된 모델을 저장합니다. 저장된 모델은 이후 호스팅을 위해 사용됩니다. \n",
    "\n",
    "학습된 모델이 추출되어 저장될 경로 또한 명시되었습니다. \n",
    "\n",
    "`training_instance_type`파라미터가 사용된 것을 확인합니다. 이 값은 본 예제의 파이프라인에서 여러번 사용됩니다. 본 단계에서는 estimator를 선언할 때 전달되었습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator_output_path: \n",
      " s3://sagemaker-us-east-1-057716757052/NCFModel/training_jobs\n"
     ]
    }
   ],
   "source": [
    "host_hyperparameters = {'epochs': 1, \n",
    "                       'lr': 0.001,\n",
    "                       'batch_size': 256,\n",
    "                       'top_k' : 10,\n",
    "                       'dropout' : 0.0,\n",
    "                       'factor_num' : 32,\n",
    "                       'num_layers' : 3,\n",
    "                       'num_ng' : 4,\n",
    "                       'test_num_ng' : 99,                   \n",
    "                    }  \n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator_output_path = f's3://{bucket}/{project_prefix}/training_jobs'\n",
    "print(\"estimator_output_path: \\n\", estimator_output_path)\n",
    "\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "instance_count = 1\n",
    "\n",
    "host_estimator = PyTorch(\n",
    "    entry_point=\"train.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    output_path = estimator_output_path,    \n",
    "    framework_version='1.8.1',\n",
    "    py_version='py3',\n",
    "    disable_profiler = True,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    session = sagemaker.Session(), # 세이지 메이커 세션\n",
    "    hyperparameters=host_hyperparameters,\n",
    "    metric_definitions = metric_definitions\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 단계에서 (프로세싱) 전처리 훈련, 검증 데이터 세트를 입력으로 제공 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name= \"NCF-Training\",\n",
    "    estimator=host_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data= s3_data_loc\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data= s3_data_loc\n",
    "        ),        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 등록 스텝\n",
    "- 모델의 성능 지표 (metrics.json) 를 등록하기 위해 ModelMetrics 오브젝트 생성.\n",
    "    - [Python SDK, class sagemaker.model_metrics.ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.MetricsSource)\n",
    "- 모델들이 저장이 될 그룹 이름을 제공하고, 모델 등록 스텝을 정의 합니다.\n",
    "- 모델 등록 단계의 개발자 가이드 \n",
    "    - [모델 등록기 단계](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model)\n",
    "    - [모델 레지스트리로 모델 등록 및 배포](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-registry.html)\n",
    "- 모델 그룹 리스팅 API:  [ListModelPackageGroups](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ListModelPackageGroups.html)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "\n",
    "# 위의 step_eval 에서 S3 로 올린 evaluation.json 파일안의 지표를 \"모델 레지스트리\" 에 모데 버전 등록시에 삽입함\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri= metric_data_uri,\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = f\"{project_prefix}\"\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name= \"NCF-Model-Registry\",\n",
    "    estimator=host_estimator,\n",
    "    image_uri= step_train.properties.AlgorithmSpecification.TrainingImage,\n",
    "    model_data= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.p2.xlarge\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌딩 파이프라인 정의\n",
    "- 파이프라인과 실험(Experiment)가 통합이 되었습니다. 이를 위한 실험 설정 파일을 같이 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.pipeline_experiment_config import PipelineExperimentConfig\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        # processing_instance_type, \n",
    "        # processing_instance_count,\n",
    "        # training_instance_type,        \n",
    "        # training_instance_count,                \n",
    "        s3_data_loc,\n",
    "        # model_eval_threshold,\n",
    "        model_approval_status,        \n",
    "    ],\n",
    "    pipeline_experiment_config=PipelineExperimentConfig(\n",
    "      ExecutionVariables.PIPELINE_NAME,\n",
    "      ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    "    ),    \n",
    "    steps=[step_train, step_register],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인을 SageMaker에 제출하고 실행하기 \n",
    "\n",
    "파이프라인 정의를 파이프라인 서비스에 제출합니다. 함께 전달되는 역할(role)을 이용하여 AWS에서 파이프라인을 생성하고 작업의 각 단계를 실행할 것입니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncfmodel',\n",
       " 'ResponseMetadata': {'RequestId': '0a7baae2-4c50-4075-a134-80c3ce1b5799',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0a7baae2-4c50-4075-a134-80c3ce1b5799',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '76',\n",
       "   'date': 'Fri, 08 Jul 2022 10:41:51 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디폴트값을 이용하여 파이프라인을 샐행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인\n",
    "\n",
    "워크플로우의 실행상황을 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncfmodel',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncfmodel/execution/wby53uv0bh27',\n",
       " 'PipelineExecutionDisplayName': 'execution-1657276912896',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2022, 7, 8, 10, 41, 52, 801000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 7, 8, 10, 41, 52, 801000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': '0ba74a8d-868b-4c91-bb7e-7f4836ef05ae',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0ba74a8d-868b-4c91-bb7e-7f4836ef05ae',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '381',\n",
       "   'date': 'Fri, 08 Jul 2022 10:41:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행된 단계들을 리스트업합니다. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'NCF-Model-Registry',\n",
       "  'StartTime': datetime.datetime(2022, 7, 8, 10, 53, 24, 251000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 8, 10, 53, 25, 342000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/14'}}},\n",
       " {'StepName': 'NCF-Training',\n",
       "  'StartTime': datetime.datetime(2022, 7, 8, 10, 41, 53, 944000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 8, 10, 53, 18, 765000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-wby53uv0bh27-ncf-training-mrmjbt7hlh'}}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 레지스트리에서 모델 등록 확인\n",
    "위에서 등록한 모델 그룹 이름을 통해서 어떤 모델이 등록되었는지를 확인 합니다.\n",
    "스튜디오에서 실제 등록된 성능 지표를 확인 할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 등록된 모델 버전에 대한 보기 --> [모델 버전의 세부 정보 보기](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-registry-details.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageSummaryList': [{'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 14,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/14',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 8, 10, 53, 25, 228000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 13,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/13',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 8, 10, 48, 45, 712000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 12,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/12',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 7, 12, 53, 11, 668000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 11,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/11',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 7, 12, 22, 31, 219000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 10,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/10',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 7, 3, 59, 13, 478000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 9,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/9',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 7, 2, 26, 1, 61000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 8,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/8',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 15, 11, 44, 996000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 7,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/7',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 14, 32, 28, 438000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 6,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/6',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 14, 18, 36, 3000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'Approved'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 5,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/5',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 14, 7, 34, 201000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 4,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/4',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 13, 33, 22, 796000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 3,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/3',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 4, 12, 50, 5, 337000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 2,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/2',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 2, 13, 20, 55, 358000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'},\n",
       "  {'ModelPackageGroupName': 'NCFModel',\n",
       "   'ModelPackageVersion': 1,\n",
       "   'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/1',\n",
       "   'CreationTime': datetime.datetime(2022, 7, 2, 9, 37, 28, 675000, tzinfo=tzlocal()),\n",
       "   'ModelPackageStatus': 'Completed',\n",
       "   'ModelApprovalStatus': 'PendingManualApproval'}],\n",
       " 'ResponseMetadata': {'RequestId': '4e5a89bf-a4d3-44e9-a07c-b41e1f247044',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4e5a89bf-a4d3-44e9-a07c-b41e1f247044',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3638',\n",
       "   'date': 'Fri, 08 Jul 2022 10:53:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 생성한 model_package_group_name 을 인자로 제공 합니다.\n",
    "response = sm_client.list_model_packages(ModelPackageGroupName= model_package_group_name)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 등록된 모델 버전의 상세 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'NCFModel',\n",
       " 'ModelPackageVersion': 14,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/14',\n",
       " 'CreationTime': datetime.datetime(2022, 7, 8, 10, 53, 25, 228000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8.1-gpu-py3',\n",
       "    'ImageDigest': 'sha256:392884aa51bb8578a98ce5d3648a0a9f36c0389113480b0e869333909d986d6a',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-057716757052/NCFModel/training_jobs/pipelines-wby53uv0bh27-NCF-Training-MrmJbt7Hlh/output/model.tar.gz'}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.xlarge'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.p2.xlarge', 'ml.m5.xlarge'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'PendingManualApproval',\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncfmodel/execution/wby53uv0bh27'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-us-east-1-057716757052/NCFModel/metrics.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'ResponseMetadata': {'RequestId': 'a64e6cd8-b2c2-448c-92da-6d578655ee16',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a64e6cd8-b2c2-448c-92da-6d578655ee16',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1236',\n",
       "   'date': 'Fri, 08 Jul 2022 10:53:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelPackageArn = response['ModelPackageSummaryList'][0]['ModelPackageArn']\n",
    "sm_client.describe_model_package(ModelPackageName=ModelPackageArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 리소스 정리: 파이프라인\n",
    "- 위에서 생성한 파이프라인을 제거 합니다.\n",
    "- isDeletePipeline=False, verbose=Fasle\n",
    "    - 파이프라인을 지우지 않고, 존재하는지 확인 합니다.\n",
    "- isDeletePipeline=False, verbose=True\n",
    "    - 파이프라인의 정의를 자세하 확인 합니다.\n",
    "- isDeletePipeline=True, verbose=True or False\n",
    "    - 파이프라인을 삭제 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.pipeline_util import clean_pipeline\n",
    "\n",
    "# # clean_pipeline(pipeline_name = pipeline_name, isDeletePipeline=False, verbose=False)   \n",
    "# clean_pipeline(pipeline_name = pipeline_name, isDeletePipeline=True, verbose=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
