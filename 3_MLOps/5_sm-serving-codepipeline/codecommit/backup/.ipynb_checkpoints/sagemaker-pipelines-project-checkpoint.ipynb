{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SageMaker Pipeline\n",
    "\n",
    "- TransformStep in Pipelines mishandling source_dir attribute (PyTorch/Script Mode)\n",
    "    - https://issuehint.com/issue/aws/sagemaker-python-sdk/2549\n",
    "\n",
    "\n",
    "### Getting some constants\n",
    "\n",
    "We get some constants from the local execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker.session.Session().default_bucket()\n",
    "\n",
    "# Change these to reflect your project/business name or if you want to separate ModelPackageGroup/Pipeline from the rest of your team\n",
    "model_package_group_name = f\"ncf-models\"\n",
    "pipeline_name = f\"ncf-pipeline-script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r s3_input_data_uri\n",
    "%store -r bucket\n",
    "%store -r project_prefix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data_dir = 'pipelines/ncf/src'\n",
    "code_artifact_name = 'source.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.py\n",
      "data_utils.py\n",
      "evaluate.py\n",
      "model.py\n",
      "requirements.txt\n",
      "train_lib.py\n",
      "train.py\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {code_data_dir} {code_artifact_name}\n",
    "code_data_dir=$1\n",
    "code_artifact_name=$2\n",
    "\n",
    "# echo $model_data_dir\n",
    "# echo $model_artifact_name\n",
    "\n",
    "cd $code_data_dir\n",
    "rm -rf $code_artifact_name\n",
    "tar -czvf $code_artifact_name *.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code_prefix = 'code'\n",
    "# S3에 저장되는 데이터의 기본 폴더 위치\n",
    "s3_code_uri = f\"s3://{bucket}/{source_code_prefix}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-04 13:22:29       6910 code/source.tar.gz\n",
      "delete: s3://sagemaker-us-east-1-057716757052/code/source.tar.gz\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {s3_code_uri} --recursive\n",
    "! aws s3 rm {s3_code_uri} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "local_code = os.path.join(code_data_dir, code_artifact_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/code\n"
     ]
    }
   ],
   "source": [
    "_ = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_code, \n",
    "    desired_s3_uri=s3_code_uri,    \n",
    ")\n",
    "print(s3_code_uri)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_code_uri = os.path.join(s3_code_uri,\"source.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the pipeline instance\n",
    "\n",
    "Here we get the pipeline instance from your pipeline module so that we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-057716757052/NCFModel/data\n",
      "s3://sagemaker-us-east-1-057716757052/code/source.tar.gz\n",
      "NCFModel\n"
     ]
    }
   ],
   "source": [
    "print(s3_input_data_uri)\n",
    "print(s3_code_uri)\n",
    "print(project_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### BASE_DIR: /home/ec2-user/SageMaker/Neural-Collaborative-Filtering-On-SageMaker/3_MLOps/3_sm-train-codepipeline/codecommit/pipelines/ncf\n",
      "estimator_output_path: \n",
      " s3://sagemaker-us-east-1-057716757052/NCFModel/training_jobs\n",
      "NCFModel exitss\n"
     ]
    }
   ],
   "source": [
    "from pipelines.ncf.pipeline import get_pipeline\n",
    "\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    s3_input_data_uri = s3_input_data_uri,\n",
    "    s3_code_uri = s3_code_uri,    \n",
    "    entry_point_code = \"train.py\",\n",
    "    project_prefix = project_prefix,\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncf-pipeline-script',\n",
       " 'ResponseMetadata': {'RequestId': 'a4166326-daf6-4b63-940a-79ad15778aa9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a4166326-daf6-4b63-940a-79ad15778aa9',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '87',\n",
       "   'date': 'Mon, 04 Jul 2022 13:57:01 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start the pipeline, accepting all the default parameters.\n",
    "\n",
    "Values can also be passed into these pipeline parameters on starting of the pipeline, and will be covered later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Now we describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncf-pipeline-script',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:057716757052:pipeline/ncf-pipeline-script/execution/tmm9dui7o9a9',\n",
       " 'PipelineExecutionDisplayName': 'execution-1656943023069',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'PipelineExperimentConfig': {'ExperimentName': 'ncf-pipeline-script',\n",
       "  'TrialName': 'tmm9dui7o9a9'},\n",
       " 'CreationTime': datetime.datetime(2022, 7, 4, 13, 57, 2, 954000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 7, 4, 13, 57, 2, 954000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {},\n",
       " 'LastModifiedBy': {},\n",
       " 'ResponseMetadata': {'RequestId': '2f45cf4e-53c1-4506-8148-c3667407c32f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2f45cf4e-53c1-4506-8148-c3667407c32f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '498',\n",
       "   'date': 'Mon, 04 Jul 2022 13:57:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'NCF-Model-Registry',\n",
       "  'StartTime': datetime.datetime(2022, 7, 4, 14, 18, 35, 201000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 4, 14, 18, 36, 109000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/6'}}},\n",
       " {'StepName': 'NCF-Training',\n",
       "  'StartTime': datetime.datetime(2022, 7, 4, 14, 7, 43, 83000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 4, 14, 18, 34, 771000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-jkld52r1x1s5-ncf-training-zazzcf3wu5'}}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Executions\n",
    "\n",
    "We can run additional executions of the pipeline specifying different pipeline parameters. The parameters argument is a dictionary whose names are the parameter names, and whose values are the primitive values to use as overrides of the defaults.\n",
    "\n",
    "Of particular note, based on the performance of the model, we may want to kick off another pipeline execution, but this time on a compute-optimized instance type and set the model approval status automatically be \"Approved\". This means that the model package version generated by the `RegisterModel` step will automatically be ready for deployment through CI/CD pipelines, such as with SageMaker Projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputData= s3_input_data_uri,\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'NCF-Model-Registry',\n",
       "  'StartTime': datetime.datetime(2022, 7, 4, 14, 18, 35, 201000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 4, 14, 18, 36, 109000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/ncfmodel/6'}}},\n",
       " {'StepName': 'NCF-Training',\n",
       "  'StartTime': datetime.datetime(2022, 7, 4, 14, 7, 43, 83000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2022, 7, 4, 14, 18, 34, 771000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'AttemptCount': 0,\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-jkld52r1x1s5-ncf-training-zazzcf3wu5'}}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
