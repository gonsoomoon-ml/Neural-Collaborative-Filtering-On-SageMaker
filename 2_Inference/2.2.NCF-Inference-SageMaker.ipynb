{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.2] 세이지 메이커 인퍼런스\n",
    "\n",
    "본 워크샵의 모든 노트북은 `conda_python3` 추가 패키지를 설치하고 모두 이 커널 에서 작업 합니다.\n",
    "\n",
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "\n",
    "- 1. 환경 셋업\n",
    "- 2. 배포 준비\n",
    "- 3. 엔드포인트 생성\n",
    "- 4. 엔드 포인트 추론\n",
    "- 5. 로컬 엔드 포인트 삭제\n",
    "\n",
    "\n",
    "---    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 노트북에서 인퍼런스 테스트를 완료한 티펙트를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r artifact_path\n",
    "%store -r bucket\n",
    "%store -r prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 배포 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 모델 아티펙트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"artifact_path: \", artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 테스트 데이터 세트 로딩\n",
    "- 로컬에서 저장된 데이터를 가져와서 데이터를 변환 합니다.\n",
    "- batch_size 만큼 데이터를 로딩하는 데이터 로더를 정의 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils \n",
    "train_data, test_data, user_num ,item_num, train_mat = data_utils.load_all(test_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 추론을 위한  데이터 세트 로딩\n",
    "- 전부 데이터를 로딩할 필요가 없지만, 여기서는 기존에 사용한 함수를 이용하기 위해서 전체 데이터를 로드 합니다. \n",
    "    - 실제 데이터로 구현시에는 따로이 로드 함수를 사용하시기를 권장 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        # self.epochs = 1        \n",
    "        self.num_ng = 4\n",
    "        self.batch_size = 256\n",
    "        self.test_num_ng = 99\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "        # self.lr = 0.001\n",
    "        self.top_k = 10\n",
    "        self.out = True\n",
    "        # self.gpu = \"0\"\n",
    "                        \n",
    "args = Params()\n",
    "print(\"# of batch_size: \", args.batch_size)\n",
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "test_dataset = data_utils.NCFData(\n",
    "\t\ttest_data, item_num, train_mat, 0, False)\n",
    "\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "\t\tbatch_size=args.test_num_ng+1, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 추론할 Paylaod 하나를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, item, label in test_loader:   \n",
    "    user_np = user.detach().cpu().numpy()\n",
    "    item_np = item.detach().cpu().numpy()            \n",
    "    break\n",
    "payload = {'user':user_np.tolist(), 'item':item_np.tolist()}\n",
    "print(\"payload: \", payload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 엔드포인트 생성\n",
    "- 이 과정은 세이지 메이커 엔드포인트를 생성합니다.\n",
    "- 7분 정도 소요 됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# instance_type = 'ml.p2.xlarge' # $ 1.831 per Hour\n",
    "instance_type = 'ml.g4dn.xlarge' # $ 0.906 per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "endpoint_name = \"sm-ncf-{}\".format(int(time.time()))\n",
    "\n",
    "\n",
    "sm_pytorch_model = PyTorchModel(model_data=artifact_path,\n",
    "                                   role=role,\n",
    "                                   entry_point='inference.py',\n",
    "                                   source_dir = 'src',\n",
    "                                   framework_version='1.8.1',\n",
    "                                   py_version='py3',\n",
    "                                   model_server_workers=1,\n",
    "                                  )\n",
    "\n",
    "sm_predictor = sm_pytorch_model.deploy(instance_type= instance_type, \n",
    "                           initial_instance_count=1, \n",
    "                           endpoint_name=endpoint_name,\n",
    "                           wait=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 엔드 포인트 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 프리딕터에 JSONSerializer 로 초기화\n",
    "- payload 로 JSON type 으로 제공하면 JSONSerializer 가 String 으로 직렬화하여 제공 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "sm_predictor.serializer = JSONSerializer('application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Boto3 invoke_endpoint() 로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "if instance_type == 'local_gpu':\n",
    "    runtime_client = sagemaker.local.LocalSagemakerRuntimeClient()    \n",
    "else:\n",
    "    runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [중요] JSON type 의 payload 를 String 으로 직렬화 해서 제공 함.\n",
    "```python\n",
    "payload_dump = json.dumps(payload)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from inference_utils import invoke_endpoint\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint(runtime_client, endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 클라우드 엔드 포인트 삭제\n",
    "- 기존에 생성한 세이지 메이커 모델, 앤드포인트 컨피그, 앤드포인트 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_utils import delete_endpoint\n",
    "\n",
    "# client = sagemaker.local.LocalSagemakerClient()\n",
    "client = boto3.Session().client('sagemaker')\n",
    "delete_endpoint(client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
